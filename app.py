# app.py
# -*- coding: utf-8 -*-

import re
import requests
import datetime as dt
import pytz
import pandas as pd
import streamlit as st
from dateutil import parser as dtparser
from st_aggrid import AgGrid, GridOptionsBuilder, JsCode, GridUpdateMode

# ======================================================================================
# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
# ======================================================================================
st.set_page_config(
    page_title="YouTube ANLT by Finkevych",
    page_icon="üìà",
    layout="wide",
)

# ======================================================================================
# API –∫–ª—é—á (–≤—à–∏—Ç–∏–π) —ñ –±–∞–∑–æ–≤–∏–π URL
# ======================================================================================
API_KEY = "AIzaSyAi5tON3ICl353D6-8MKUSalT2gqkwNbYA"
YOUTUBE_API = "https://www.googleapis.com/youtube/v3"
TZ_NAME = "Europe/Kyiv"   # —Ñ—ñ–∫—Å–æ–≤–∞–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–∞ —Ç–∞–π–º–∑–æ–Ω–∞

# ======================================================================================
# PRESETS ‚Äî –≥–æ—Ç–æ–≤—ñ –Ω–∞–±–æ—Ä–∏ –∫–∞–Ω–∞–ª—ñ–≤ (—Ä–µ–¥–∞–≥—É–π –ø—ñ–¥ —Å–µ–±–µ)
# ======================================================================================
PRESETS = {
    "Ethereal Vibes": [
        "https://www.youtube.com/@Just_AI_Dance", "https://www.youtube.com/@ImRavina", "https://www.youtube.com/@Ryusias_day", "https://www.youtube.com/@MyMelodyMuse", "https://www.youtube.com/@melodyisheremusic",
        "https://www.youtube.com/@vanessa-vlog-5uj", "https://www.youtube.com/@melodyvibesworlds", "https://www.youtube.com/@LaurielNoir/featured", "https://www.youtube.com/@misssweet-video/videos",
        "https://www.youtube.com/@CandyBabe-n2d", "https://www.youtube.com/@NamiaRhea", "https://www.youtube.com/@Charming-girl-video", 
        "https://www.youtube.com/@Eunbiai", "https://www.youtube.com/@SarahTaylorai", "https://www.youtube.com/@IvyRoseai", "https://www.youtube.com/@charmingmusicvibes",
        "https://www.youtube.com/@AIÁªùËâ≤Ê∑ªÈ¶ô", "https://www.youtube.com/@LeeYunaai", "https://www.youtube.com/@AIVlogLookbook/featured",
        "https://www.youtube.com/@MeliaLune/featured", "https://www.youtube.com/@ArinsMemory", "https://www.youtube.com/@DreamyisHere-k3n",
        "https://www.youtube.com/@sherryishere4yt", "https://www.youtube.com/@GinzanoKage", 
        # –¥–æ–¥–∞–π —Å—é–¥–∏ —ñ–Ω—à—ñ –∫–∞–Ω–∞–ª–∏...
    ],
    "Yumi Vibes": [
        "https://www.youtube.com/@Just_AI_Dance", "https://www.youtube.com/@MyMelodyMuse", "https://www.youtube.com/@melodyisheremusic",
        "https://www.youtube.com/@vanessa-vlog-5uj", "https://www.youtube.com/@melodyvibesworlds", "https://www.youtube.com/@LaurielNoir/featured", 
        "https://www.youtube.com/@CandyBabe-n2d", "https://www.youtube.com/@NamiaRhea", "https://www.youtube.com/@Charming-girl-video", 
        "https://www.youtube.com/@Eunbiai", "https://www.youtube.com/@SarahTaylorai", "https://www.youtube.com/@IvyRoseai", "https://www.youtube.com/@charmingmusicvibes",
        "https://www.youtube.com/@AIÁªùËâ≤Ê∑ªÈ¶ô", "https://www.youtube.com/@LeeYunaai", "https://www.youtube.com/@AIVlogLookbook/featured",
        "https://www.youtube.com/@MeliaLune/featured", "https://www.youtube.com/@ArinsMemory", "https://www.youtube.com/@DreamyisHere-k3n",
        "https://www.youtube.com/@sherryishere4yt", "https://www.youtube.com/@GinzanoKage", "https://www.youtube.com/@melodyvibesworlds", 
        # –¥–æ–¥–∞–π —Å—é–¥–∏ —ñ–Ω—à—ñ –∫–∞–Ω–∞–ª–∏...
    ],
}

# ======================================================================================
# –°—Ç–∞–Ω
# ======================================================================================
if "ran" not in st.session_state:
    st.session_state.ran = False
if "channels_text" not in st.session_state:
    st.session_state.channels_text = ""
if "sort_by" not in st.session_state:
    st.session_state.sort_by = "–ó–∞ Viral"

# ======================================================================================
# –£—Ç–∏–ª—ñ—Ç–∏
# ======================================================================================
def format_int(n: int | float | None) -> str:
    if n is None or (isinstance(n, float) and pd.isna(n)):
        return ""
    try:
        n = int(n)
    except Exception:
        return ""
    return f"{n:,}".replace(",", " ")

def format_vph(v: float | None) -> str:
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return ""
    try:
        return f"{int(round(v))}"
    except Exception:
        return ""

def format_multiplier(v: float | None) -> str:
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return ""
    return f"{v:.1f}x"

def parse_hms_to_seconds(s: str) -> int | None:
    if not s:
        return None
    s = s.strip()
    if not re.fullmatch(r"\d{1,2}:\d{1,2}:\d{1,2}|\d{1,2}:\d{1,2}|\d{1,5}", s):
        return None
    parts = [int(p) for p in s.split(":")]
    if len(parts) == 3:
        h, m, s2 = parts
        return h * 3600 + m * 60 + s2
    if len(parts) == 2:
        m, s2 = parts
        return m * 60 + s2
    return int(parts[0])

_ISO8601_DURATION = re.compile(
    r"^P(?:(?P<days>\d+)D)?(?:T(?:(?P<hours>\d+)H)?(?:(?P<minutes>\d+)M)?(?:(?P<seconds>\d+)S)?)?$"
)
def iso8601_duration_to_seconds(dur: str) -> int:
    if not dur:
        return 0
    m = _ISO8601_DURATION.match(dur)
    if not m:
        return 0
    days = int(m.group("days") or 0)
    hours = int(m.group("hours") or 0)
    minutes = int(m.group("minutes") or 0)
    seconds = int(m.group("seconds") or 0)
    return days * 86400 + hours * 3600 + minutes * 60 + seconds

def ensure_api_key():
    if not API_KEY:
        st.error("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ YouTube API –∫–ª—é—á. –û—á—ñ–∫—É—î—Ç—å—Å—è —É –∑–º—ñ–Ω–Ω—ñ–π `API_KEY` –∑–≤–µ—Ä—Ö—É —Ñ–∞–π–ª—É.")
        st.stop()

def localize_and_format(ts_utc: dt.datetime, tzname: str) -> str:
    tz = pytz.timezone(tzname)
    local_dt = ts_utc.astimezone(tz)
    return local_dt.strftime("%Y-%m-%d %H:%M")

def extract_channel_id(text: str) -> dict:
    text = text.strip()
    if text.startswith("@"):
        return {"type": "handle", "value": text[1:]}
    m = re.search(r"(?:youtube\.com\/channel\/)(UC[0-9A-Za-z_-]{22})", text)
    if m:
        return {"type": "channel_id", "value": m.group(1)}
    m2 = re.search(r"(?:youtube\.com\/@)([A-Za-z0-9._-]+)", text)
    if m2:
        return {"type": "handle", "value": m2.group(1)}
    return {"type": "search", "value": text}

# ======================================================================================
# API –∫–ª—ñ—î–Ω—Ç
# ======================================================================================
def yt_get(path: str, params: dict) -> dict:
    ensure_api_key()
    final = {"key": API_KEY, **params}
    r = requests.get(f"{YOUTUBE_API}/{path}", params=final, timeout=30)
    r.raise_for_status()
    return r.json()

def resolve_channel(q: str) -> dict | None:
    cls = extract_channel_id(q)
    if cls["type"] == "handle":
        data = yt_get("channels", {"part": "snippet,statistics,contentDetails", "forHandle": f"@{cls['value']}"})
        if data.get("items"):
            it = data["items"][0]
            return {
                "id": it["id"],
                "title": it["snippet"]["title"],
                "subscribers": int(it.get("statistics", {}).get("subscriberCount", 0))
                if it.get("statistics", {}).get("hiddenSubscriberCount") is not True else None,
                "uploads": it["contentDetails"]["relatedPlaylists"]["uploads"],
            }
    if cls["type"] == "channel_id":
        data = yt_get("channels", {"part": "snippet,statistics,contentDetails", "id": cls["value"]})
        if data.get("items"):
            it = data["items"][0]
            return {
                "id": it["id"],
                "title": it["snippet"]["title"],
                "subscribers": int(it.get("statistics", {}).get("subscriberCount", 0))
                if it.get("statistics", {}).get("hiddenSubscriberCount") is not True else None,
                "uploads": it["contentDetails"]["relatedPlaylists"]["uploads"],
            }
    data = yt_get("search", {"part": "snippet", "q": cls["value"], "type": "channel", "maxResults": 1})
    if data.get("items"):
        ch_id = data["items"][0]["snippet"]["channelId"]
        data2 = yt_get("channels", {"part": "snippet,statistics,contentDetails", "id": ch_id})
        if data2.get("items"):
            it = data2["items"][0]
            return {
                "id": it["id"],
                "title": it["snippet"]["title"],
                "subscribers": int(it.get("statistics", {}).get("subscriberCount", 0))
                if it.get("statistics", {}).get("hiddenSubscriberCount") is not True else None,
                "uploads": it["contentDetails"]["relatedPlaylists"]["uploads"],
            }
    return None

def iterate_playlist_items(playlist_id: str, page_limit: int = 50):
    token = None
    pages = 0
    while True:
        payload = {"part": "contentDetails,snippet", "playlistId": playlist_id, "maxResults": 50, "pageToken": token or ""}
        data = yt_get("playlistItems", payload)
        yield data
        token = data.get("nextPageToken")
        pages += 1
        if not token or pages >= page_limit:
            break

def videos_batch(video_ids: list[str]) -> dict:
    if not video_ids:
        return {"items": []}
    return yt_get(
        "videos",
        {"part": "snippet,statistics,contentDetails,liveStreamingDetails", "id": ",".join(video_ids), "maxResults": 50},
    )

# ======================================================================================
# UI ‚Äî –≤—Å–µ –Ω–∞ –æ–¥–Ω—ñ–π —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ
# ======================================================================================
st.title("üìà BladeGrid YouTube Analytics by Finkevych")

st.markdown("### –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
left, right = st.columns([3, 1])

# –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–µ—Å–µ—Ç–∏ (–º–æ–∂—É—Ç—å –∑–º—ñ–Ω—é–≤–∞—Ç–∏ session_state –î–û —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è textarea)
def apply_preset():
    name = st.session_state.get("preset_choice")
    if name in PRESETS:
        st.session_state["channels_text"] = "\n".join(PRESETS[name])

with right:
    st.selectbox("–ù–∞–±—ñ—Ä –∫–∞–Ω–∞–ª—ñ–≤", ["‚Äî –û–±—Ä–∞—Ç–∏ ‚Äî"] + list(PRESETS.keys()),
                 index=0, key="preset_choice")
    st.button("–ó–∞–ø–æ–≤–Ω–∏—Ç–∏ –∫–∞–Ω–∞–ª–∏", use_container_width=True, on_click=apply_preset)

with left:
    st.text_area(
        "–°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª—ñ–≤ –ø–æ –æ–¥–Ω–æ–º—É –≤ —Ä—è–¥–æ–∫. –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ @username –∞–±–æ –ø–æ–≤–Ω–∏—Ö URL",
        key="channels_text",
        height=160,
        placeholder="@MrBeast\nhttps://www.youtube.com/@veritasium\nhttps://www.youtube.com/channel/UC-lHJZR3Gqxm24_Vd_AJ5Yw",
    )

c1, c2, c3 = st.columns([1, 1, 2])
with c1:
    min_hms = st.text_input("–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å (–≤—ñ–¥)", value="0:00:60")        # 60 —Å–µ–∫—É–Ω–¥
with c2:
    max_hms = st.text_input("–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å (–¥–æ)", value="2:00:00")    # 2 –≥–æ–¥–∏–Ω–∏
with c3:
    today_local = dt.datetime.now(pytz.timezone(TZ_NAME)).date()
    date_from, date_to = st.date_input(
        "–î—ñ–∞–ø–∞–∑–æ–Ω –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–∏—Ö –≤—ñ–¥–µ–æ",
        value=(today_local - dt.timedelta(days=5), today_local),
    )

sort_options = ["–ó–∞ Viral", "–ó–∞ –¥–∞—Ç–æ—é", "–ó–∞ –ø–µ—Ä–µ–≥–ª—è–¥–∞–º–∏", "–ó–∞ VPH", "–ó–∞ Multiplier"]
sort_by = st.selectbox(
    "–°–æ—Ä—Ç—É–≤–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:",
    options=sort_options,
    index=sort_options.index(st.session_state.sort_by),
    key="sort_by",
)

if st.button("–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏", type="primary"):
    st.session_state.ran = True

if not st.session_state.ran:
    st.stop()

# ======================================================================================
# –í–∞–ª—ñ–¥–∞—Ü—ñ—ó —ñ –º–µ–∂—ñ
# ======================================================================================
channels_input = st.session_state.channels_text
if not channels_input.strip():
    st.warning("–í–≤–µ–¥–∏ —Ö–æ—á –æ–¥–∏–Ω –∫–∞–Ω–∞–ª –∞–±–æ –æ–±–µ—Ä–∏ –Ω–∞–±—ñ—Ä —ñ –Ω–∞—Ç–∏—Å–Ω–∏ ¬´–ó–∞–ø–æ–≤–Ω–∏—Ç–∏ –∫–∞–Ω–∞–ª–∏¬ª.")
    st.stop()

def parse_hms_optional(s): return parse_hms_to_seconds(s) if s else None
min_secs = parse_hms_optional(min_hms)
max_secs = parse_hms_optional(max_hms)
if min_secs is not None and max_secs is not None and min_secs > max_secs:
    st.error("–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π —Ñ—ñ–ª—å—Ç—Ä —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ: '–í—ñ–¥' > '–î–æ'.")
    st.stop()

ensure_api_key()
tz = pytz.timezone(TZ_NAME)
start_local = dt.datetime.combine(date_from, dt.time.min).replace(tzinfo=tz)
end_local   = dt.datetime.combine(date_to,   dt.time.max).replace(tzinfo=tz)
start_utc = start_local.astimezone(pytz.UTC)
end_utc   = end_local.astimezone(pytz.UTC)
now_utc   = dt.datetime.now(pytz.UTC)

# ======================================================================================
# –ó–±—ñ—Ä –¥–∞–Ω–∏—Ö
# ======================================================================================
rows = []
for line in [ln.strip() for ln in channels_input.splitlines() if ln.strip()]:
    ch = resolve_channel(line)
    if not ch:
        st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –∫–∞–Ω–∞–ª –¥–ª—è ¬´{line}¬ª. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
        continue

    uploads_id    = ch["uploads"]
    subscribers   = ch["subscribers"]
    channel_title = ch["title"]

    early_stop = False
    for page in iterate_playlist_items(uploads_id, page_limit=80):
        items = page.get("items", [])
        if not items:
            continue

        video_ids = []
        per_item_snippets = {}
        for it in items:
            vid = it.get("contentDetails", {}).get("videoId")
            if not vid:
                continue
            sn = it.get("snippet", {})
            lbc = (sn.get("liveBroadcastContent") or "").lower()
            if lbc in {"live", "upcoming"}:
                continue
            video_ids.append(vid)
            per_item_snippets[vid] = sn

        if not video_ids:
            continue

        data_v = videos_batch(video_ids)
        for v in data_v.get("items", []):
            vid = v["id"]
            sn  = v.get("snippet", {}) or per_item_snippets.get(vid, {})
            stt = v.get("statistics", {})
            cd  = v.get("contentDetails", {})
            lsd = v.get("liveStreamingDetails")

            lbc2 = (sn.get("liveBroadcastContent") or "").lower()
            is_live_now = (lbc2 == "live") and lsd and not lsd.get("actualEndTime")
            if lbc2 == "upcoming" or is_live_now:
                continue

            published_iso = cd.get("videoPublishedAt") or sn.get("publishedAt")
            if not published_iso:
                continue
            try:
                published_utc = dtparser.isoparse(published_iso).astimezone(pytz.UTC)
            except Exception:
                continue

            if published_utc < start_utc - dt.timedelta(days=2):
                early_stop = True
            if not (start_utc <= published_utc <= end_utc):
                continue

            dur_sec = iso8601_duration_to_seconds(cd.get("duration", ""))

            if min_secs is not None and dur_sec < min_secs:
                continue
            if max_secs is not None and dur_sec > max_secs:
                continue

            try:
                views = int(stt.get("viewCount", 0))
            except Exception:
                views = 0

            age_hours = max((now_utc - published_utc).total_seconds() / 3600.0, 1/60)  # –º—ñ–Ω. 1 —Ö–≤
            vph = views / age_hours if age_hours > 0 else 0.0
            multiplier = (views / subscribers) if subscribers and subscribers > 0 else None

            if dur_sec >= 3600:
                dur_str = f"{dur_sec // 3600}:{(dur_sec % 3600)//60:02d}:{dur_sec % 60:02d}"
            else:
                dur_str = f"{dur_sec // 60}:{dur_sec % 60:02d}"

            title = sn.get("title", "")
            url   = f"https://www.youtube.com/watch?v={vid}"
            published_local_str = localize_and_format(published_utc, TZ_NAME)

            rows.append({
                "–ö–∞–Ω–∞–ª": channel_title,
                "–ù–∞–∑–≤–∞ –≤—ñ–¥–µ–æ": title,
                "–ü—ñ–¥–ø–∏—Å–Ω–∏–∫–∏": subscribers,
                "–ü–µ—Ä–µ–≥–ª—è–¥–∏": views,               # raw –¥–æ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è
                "Multiplier_raw": multiplier if multiplier is not None else float("nan"),
                "Multiplier": None,               # –∑–∞–ø–æ–≤–Ω–∏–º–æ —Ñ–æ—Ä–º–∞—Ç –ø—ñ–∑–Ω—ñ—à–µ
                "VPH_raw": vph,
                "VPH": None,
                "–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å": dur_str,
                "–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ": published_local_str,
                "UTC_Published": published_utc,
                "URL": url,                       # –ø—Ä–æ—Å—Ç–∏–π —Ç–µ–∫—Å—Ç ‚Äî –ª–µ–≥–∫–æ –∫–æ–ø—ñ—é–≤–∞—Ç–∏
                "age_hours": age_hours,
            })

        if early_stop:
            break

if not rows:
    st.warning("–ó–∞ –∑–∞–¥–∞–Ω–∏–º–∏ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏ –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
    st.stop()

df = pd.DataFrame(rows)

# ======================================================================================
# VIRAL (–∫–∞–ª—ñ–±—Ä–æ–≤–∞–Ω–∞ —à–∫–∞–ª–∞ —É ‚Äú—ñ–∫—Å–∞—Ö‚Äù)
#  –ï—Ç–∞–ª–æ–Ω: 100k views –∑–∞ 24 –≥–æ–¥ –Ω–∞ –∫–∞–Ω–∞–ª—ñ –∑ 100k subs ‚âà 10x;
#          1M views –∑–∞ 24 –≥–æ–¥ –Ω–∞ 100k subs ‚âà 100x.
# ======================================================================================
ALPHA_H = 0.5   # –≥–æ–¥ ‚Äî –∞–Ω—Ç–∏—à—É–º –¥–ª—è –¥—É–∂–µ —Å–≤—ñ–∂–∏—Ö –≤—ñ–¥–µ–æ
C = 10.0 * (24.0 + ALPHA_H) / 24.0  # ~10.2083

# multiplier: —è–∫—â–æ –ø—ñ–¥–ø–∏—Å–Ω–∏–∫–∏ –Ω–µ–≤—ñ–¥–æ–º—ñ ‚Äî –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ 1.0x, —â–æ–± –Ω–µ –∑–∞–Ω–∏–∂—É–≤–∞—Ç–∏ –≤—ñ–¥–µ–æ
m = df["Multiplier_raw"].where(pd.notna(df["Multiplier_raw"]), 1.0)

fresh = 24.0 / (df["age_hours"] + ALPHA_H)
df["Viral_raw"] = C * m * fresh
df["Viral"] = df["Viral_raw"].apply(lambda v: f"{v:.1f}x")

# ======================================================================================
# –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è (–¥–µ—Ñ–æ–ª—Ç ‚Äî –ó–∞ Viral)
# ======================================================================================
if sort_by == "–ó–∞ Viral":
    df = df.sort_values("Viral_raw", ascending=False)
elif sort_by == "–ó–∞ –¥–∞—Ç–æ—é":
    df = df.sort_values("UTC_Published", ascending=False)
elif sort_by == "–ó–∞ –ø–µ—Ä–µ–≥–ª—è–¥–∞–º–∏":
    df = df.sort_values("–ü–µ—Ä–µ–≥–ª—è–¥–∏", ascending=False)
elif sort_by == "–ó–∞ VPH":
    df = df.sort_values("VPH_raw", ascending=False)
elif sort_by == "–ó–∞ Multiplier":
    df = df.sort_values("Multiplier_raw", ascending=False, na_position="last")

# ======================================================================================
# –§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
# ======================================================================================
df["–ü—ñ–¥–ø–∏—Å–Ω–∏–∫–∏"] = df["–ü—ñ–¥–ø–∏—Å–Ω–∏–∫–∏"].apply(lambda x: format_int(x) if pd.notna(x) and x else "")
df["–ü–µ—Ä–µ–≥–ª—è–¥–∏"]  = df["–ü–µ—Ä–µ–≥–ª—è–¥–∏"].apply(format_int)
df["Multiplier"] = df["Multiplier_raw"].apply(lambda v: format_multiplier(v) if pd.notna(v) else "")
df["VPH"]        = df["VPH_raw"].apply(format_vph)

# –ü–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫: Viral –º—ñ–∂ ‚Äú–ü–µ—Ä–µ–≥–ª—è–¥–∏‚Äù —ñ ‚ÄúMultiplier‚Äù
columns_order = [
    "–ö–∞–Ω–∞–ª","–ù–∞–∑–≤–∞ –≤—ñ–¥–µ–æ","–ü—ñ–¥–ø–∏—Å–Ω–∏–∫–∏","–ü–µ—Ä–µ–≥–ª—è–¥–∏","Viral","Multiplier","VPH",
    "–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å","–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ","URL"
]
df_show = df[columns_order].copy()

st.markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç–∏")

# ======================================================================================
# AG Grid ‚Äî AUTOSIZE + –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –∫–æ–ø—ñ—é–≤–∞—Ç–∏
# ======================================================================================
gob = GridOptionsBuilder.from_dataframe(df_show)
gob.configure_default_column(
    resizable=True, sortable=True, filter=True, wrapText=False, autoHeight=False,
    cellStyle={"textAlign":"left"}
)
gob.configure_column("–ù–∞–∑–≤–∞ –≤—ñ–¥–µ–æ", width=420)
gob.configure_column("URL", width=360)
for c in ["–ü—ñ–¥–ø–∏—Å–Ω–∏–∫–∏","–ü–µ—Ä–µ–≥–ª—è–¥–∏","Viral","Multiplier","VPH","–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å","–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ"]:
    gob.configure_column(c, width=140)

grid_opts = gob.build()
grid_opts.update({
    "enableCellTextSelection": True,   # –º–æ–∂–Ω–∞ –≤–∏–¥—ñ–ª—è—Ç–∏ —ñ –∫–æ–ø—ñ—é–≤–∞—Ç–∏
    "ensureDomOrder": True,
    "suppressRowClickSelection": True,
})
grid_opts["onFirstDataRendered"] = JsCode("""
function(e){
  try{
    e.api.sizeColumnsToFit();
    setTimeout(function(){
      const all=[]; e.columnApi.getAllColumns().forEach(c=>all.push(c.getColId()));
      e.columnApi.autoSizeColumns(all, false);
    }, 50);
  }catch(err){console.warn(err);}
}
""")

AgGrid(
    df_show,
    gridOptions=grid_opts,
    height=600,
    fit_columns_on_grid_load=False,
    allow_unsafe_jscode=True,
    enable_enterprise_modules=False,
    update_mode=GridUpdateMode.NO_UPDATE,
    theme="balham",
)

# –ü—ñ–¥—Å—É–º–æ–∫
st.success(
    f"–ó–Ω–∞–π–¥–µ–Ω–æ –≤—ñ–¥–µ–æ: **{len(df_show):,}** | –ö–∞–Ω–∞–ª—ñ–≤: **{len(set(df['–ö–∞–Ω–∞–ª'])):,}** | "
    f"–î—ñ–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: **{date_from.strftime('%Y-%m-%d')} ‚Üí {date_to.strftime('%Y-%m-%d')} ({TZ_NAME})**"
)
